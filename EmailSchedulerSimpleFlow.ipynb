{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f81802aa-ff02-4301-872a-932d6725f8e8",
   "metadata": {},
   "source": [
    "A DIY AI-drive Email-Based Meeting Scheduler agent\n",
    "===\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc672d08-9527-4384-95fa-2bfa3b0abdf8",
   "metadata": {},
   "source": [
    "Introduction\n",
    "---\n",
    "\n",
    "Large Language Models (LLMs) have unlocked new paradigms in automation and intelligent systems design, where agents when powered by LLMs, can plan, reason, and interact with tools or other agents to achieve complex objectives. The purpose of this notebook is to illustrates these principles through a toy example: the agent reads emails that are requests for scheduling meetings, finds available times in the calendar, schedules them, and sends confirmations to the requestor. This implementation is built from scratch, without relying on popular agentic frameworks like LangChain, CrewAI, AWS Bedrock Agents so that we can understand the principles behind such systems and components involved in builiding such systems. It also demonstrates how (natural) language can be used as a flexible and powerful interface between system components. The example also shows how we can use LLM to determine if we need to abort or terminate prematurely due to failures or exceptional conditions when executing the task plan.\n",
    "\n",
    "Pre-requisites:\n",
    "* Google email and calendar python APIs are used to read emails and google calendar to schedule the meetings. Get necessary permissions with Google services and download the authentication credentials as a local JSON file. Please refer to Google's official documentation for step-by-step instructions on how to complete this setup.\n",
    "* Anthropic Sonnet model is used for LLM through AWS Bedrock conversation API. Enable Anthropic Claude 3 Sonnet model in your AWS account and verify that you are able be able to connect to it via boto library."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f3b3aa8-1c9f-40be-b91c-60a69fe9780a",
   "metadata": {},
   "source": [
    "Implementation\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f3b407d-bd8c-41ae-b6cb-b4565703bc85",
   "metadata": {},
   "source": [
    "Start importing libraries we would be using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec87a02-50d6-4bc5-9b96-6c33d9491a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import datetime\n",
    "import email\n",
    "import json\n",
    "import os\n",
    "import os.path\n",
    "import pickle\n",
    "import re\n",
    "import subprocess\n",
    "import time\n",
    "import traceback\n",
    "\n",
    "from typing import Optional, NamedTuple\n",
    "\n",
    "from dateutil import parser, tz\n",
    "from datetime import datetime, date, time, timedelta\n",
    "from email.mime.text import MIMEText\n",
    "\n",
    "import boto3\n",
    "import requests\n",
    "from google.auth.transport.requests import Request\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.errors import HttpError"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2ebc6c-6b28-4e0d-adad-e6fa98dcd908",
   "metadata": {},
   "source": [
    "GOOGLE_CREDENTALS points to a google authentication credentials in the local file system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc510c4-9614-4149-b8b4-b1392e51fd4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "GOOGLE_CREDENTALS = \"<full path to google client secret json file, something like client_secret_...apps.googleusercontent.com.json>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05efa2c5-f5ea-4baf-8248-37b6eb733bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maximum number of emails to read to find a meeting request. Gives up if not found any in this range.\n",
    "MAX_EMAILS_TO_READ = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c33e8d6-5324-47dd-9bc4-81b408402157",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anthropic model id, make sure to get permissions to it in your AWS account\n",
    "\n",
    "MODEL_ID = \"anthropic.claude-3-sonnet-20240229-v1:0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35100e37-45cc-4ea3-a3d2-80b228a8d67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GoogleServices:\n",
    "\n",
    "    \"\"\"\n",
    "    This class encapsulates all interactions with google services like email and calendar.\n",
    "    \"\"\"\n",
    "    \n",
    "    # WARNING: If modifying these scopes, delete the cache file token.pickle\n",
    "    SCOPES = ['https://www.googleapis.com/auth/gmail.readonly',\n",
    "              'https://www.googleapis.com/auth/gmail.send',\n",
    "              'https://www.googleapis.com/auth/gmail.modify',\n",
    "              'https://www.googleapis.com/auth/calendar.events'\n",
    "             ]\n",
    "\n",
    "    def __init__(self, credentials_json):\n",
    "        self.creds = self._google_authenticate(credentials_json, GoogleServices.SCOPES)\n",
    "        self.gmail_service = self._get_gmail_service(self.creds)\n",
    "        self.google_calendar_service = self._get_google_calendar_service(self.creds)\n",
    "\n",
    "    def _get_gmail_service(self, creds):\n",
    "        return build('gmail', 'v1', credentials=creds)\n",
    "\n",
    "    def _get_google_calendar_service(self, creds):\n",
    "        return build(\"calendar\", \"v3\", credentials=creds)    \n",
    "    \n",
    "    def _google_authenticate(self, creds_json, scopes):\n",
    "        creds = None\n",
    "        if os.path.exists('token.pickle'):\n",
    "            with open('token.pickle', 'rb') as token:\n",
    "                creds = pickle.load(token)\n",
    "        if not creds or not creds.valid:\n",
    "            if creds and creds.expired and creds.refresh_token:\n",
    "                creds.refresh(Request())\n",
    "            else:\n",
    "                flow = InstalledAppFlow.from_client_secrets_file(creds_json, scopes)\n",
    "                creds = flow.run_local_server(port=0)\n",
    "            with open('token.pickle', 'wb') as token:\n",
    "                pickle.dump(creds, token)\n",
    "    \n",
    "        return creds\n",
    "\n",
    "    def _create_message(self, sender, to, subject, message_text):\n",
    "        message = MIMEText(message_text)\n",
    "        message['to'] = to\n",
    "        message['from'] = sender\n",
    "        message['subject'] = subject\n",
    "        raw_message = base64.urlsafe_b64encode(message.as_bytes())\n",
    "        return {'raw': raw_message.decode()}\n",
    "    \n",
    "    def send_message(self, sender, to, message_text, message_subject = \"Test Email via Gmail API\"):        \n",
    "        message = self._create_message(sender, to, message_subject, message_text)\n",
    "        message = self.gmail_service.users().messages().send(userId=\"me\", body=message).execute()\n",
    "        print(f'Message sent: {message[\"id\"]}')\n",
    "\n",
    "    def mark_message_read(self, msg_id):\n",
    "        self.gmail_service.users().messages().modify(userId='me', id=msg_id, body={'removeLabelIds': ['UNREAD']}).execute()\n",
    "\n",
    "    def get_message(self, msg_id):\n",
    "    \n",
    "        try:\n",
    "            message_list = self.gmail_service.users().messages().get(userId='me', id=msg_id, format='raw').execute()\n",
    "    \n",
    "            msg_raw = base64.urlsafe_b64decode(message_list['raw'].encode('ASCII'))\n",
    "    \n",
    "            msg_str = email.message_from_bytes(msg_raw)\n",
    "\n",
    "            \n",
    "            sender = msg_str['from']\n",
    "            to = msg_str['to']\n",
    "\n",
    "            content_types = msg_str.get_content_maintype()\n",
    "            \n",
    "            if content_types == 'multipart':\n",
    "                part1, part2 = msg_str.get_payload()\n",
    "                if self._is_base64(part1.get_payload()):\n",
    "                    part1_decoded = base64.b64decode(part1.get_payload()) \n",
    "                else:\n",
    "                    part1_decoded = part1.get_payload()\n",
    "                return {\"from\": sender, \"to\" : to, \"body\": part1_decoded }\n",
    "            else:\n",
    "                return {\"from\": sender, \"to\" : to, \"id\": msg_id, \"body\": msg_str.get_payload() }    \n",
    "    \n",
    "        except HttpError as error:\n",
    "            # TODO - Handle errors from gmail API.\n",
    "            print(f'An error occurred: {error}')\n",
    "\n",
    "    def _get_events(self):\n",
    "        try:\n",
    "            now = datetime.utcnow().isoformat() + \"Z\"\n",
    "            # This is a toy program -- a more robust solution would get all events in a date/time range\n",
    "            events_result = (\n",
    "                self.google_calendar_service.events()\n",
    "                .list(\n",
    "                    calendarId=\"primary\",\n",
    "                    timeMin=now,\n",
    "                    maxResults=25,\n",
    "                    singleEvents=True,\n",
    "                    orderBy=\"startTime\",\n",
    "                )\n",
    "                .execute()\n",
    "            )\n",
    "            events = events_result.get(\"items\", [])\n",
    "            \n",
    "            if not events:\n",
    "                print(\"No upcoming events found.\")\n",
    "                return []\n",
    "    \n",
    "            # Prints the start and name of the next 10 events\n",
    "            for event in events:\n",
    "                start = event[\"start\"].get(\"dateTime\", event[\"start\"].get(\"date\"))\n",
    "    \n",
    "            return events\n",
    "            \n",
    "        except HttpError as error:\n",
    "            print(f\"An error occurred: {error}\")\n",
    "        return []\n",
    "    \n",
    "    def simple_events(self):\n",
    "\n",
    "        events = self._get_events()\n",
    "        \n",
    "        summaries = []\n",
    "        \n",
    "        for event in events:\n",
    "            start = event[\"start\"].get(\"dateTime\", event[\"start\"].get(\"date\"))\n",
    "            end = event[\"end\"].get(\"dateTime\", event[\"end\"].get(\"date\"))\n",
    "            summary = event.get(\"summary\", \"There is no summary for the event\")\n",
    "            desc = event.get(\"description\", \"There is no description for the event\")\n",
    "            summaries.append({\"start\": start, \"end\": end, \"summary\": summary, \"description\": desc})\n",
    "    \n",
    "        return summaries\n",
    "\n",
    "    def _convert_end_datetime(self, start, duration):\n",
    "        start_dt = parser.isoparse(start)\n",
    "        delta = timedelta(minutes=int(duration))\n",
    "        end_dt = start_dt + delta\n",
    "        return end_dt.isoformat()\n",
    "\n",
    "    def create_calendar_event(self, summary, start, duration):\n",
    "\n",
    "        duration = int(duration) # llm response that passed here is string\n",
    "        \n",
    "        end = self._convert_end_datetime(start, duration)\n",
    "        \n",
    "        event = {\n",
    "          'summary': summary,\n",
    "          'description': summary,\n",
    "          'start': {\n",
    "            'dateTime': start\n",
    "          },\n",
    "          'end': {\n",
    "            'dateTime': end,\n",
    "          },\n",
    "          'visibility': 'public'\n",
    "        }\n",
    "        event = self.google_calendar_service.events().insert(calendarId='primary', body=event).execute()\n",
    "        response = f\"Event created: {event.get('htmlLink')}. Event start date/time: {start} and end date/time: {end}\"\n",
    "        return response\n",
    "\n",
    "    def _is_base64(self, s: str) -> bool:\n",
    "        # Check valid characters and length\n",
    "        if not re.fullmatch(r'^[A-Za-z0-9+/]*={0,2}$', s):\n",
    "            return False\n",
    "        if len(s) % 4 != 0:\n",
    "            return False\n",
    "    \n",
    "        try:\n",
    "            # Try decoding and re-encoding to see if matches\n",
    "            decoded = base64.b64decode(s, validate=True)\n",
    "            return base64.b64encode(decoded).decode('utf-8').rstrip('=') == s.rstrip('=')\n",
    "        except Exception:\n",
    "            return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb49475a-0dfe-4cb8-8f53-7bf40db0f1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Llm:\n",
    "    \"\"\"\n",
    "    Just a wrapper to AWS Bedrock API\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, runtime, model):\n",
    "        self.runtime = runtime\n",
    "        self.model = model\n",
    "\n",
    "    def invoke(self, sys_prompt, user_prompt, verbose=False):\n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [{ \n",
    "                    \"text\": user_prompt,\n",
    "                }]\n",
    "            }\n",
    "        ]\n",
    "        system = [\n",
    "            {\n",
    "                \"text\": sys_prompt\n",
    "            }\n",
    "        ]\n",
    "    \n",
    "        if (verbose):\n",
    "            print(\"--------\")        \n",
    "            print(sys_prompt)\n",
    "            print(user_prompt)\n",
    "    \n",
    "        infcfg = {\n",
    "            'maxTokens': 4096,\n",
    "            'temperature': 0\n",
    "        }\n",
    "        response = self.runtime.converse(\n",
    "            messages=messages,\n",
    "            system=system,\n",
    "            modelId = self.model, \n",
    "            inferenceConfig = infcfg)\n",
    "        if verbose:\n",
    "            print(response)\n",
    "            print(\"--------\")\n",
    "        return response[\"output\"][\"message\"][\"content\"][0][\"text\"]\n",
    "\n",
    "    def __call__(self, sys_prompt, user_prompt, verbose=False):\n",
    "        return self.invoke(sys_prompt, user_prompt, verbose)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac4acb4d-56f6-44f4-b733-768d17685ae9",
   "metadata": {},
   "source": [
    "**Notes**\n",
    "* Opted to use global functions for most interactions with the LLM and tools to keep the code minimal and easy to follow, avoiding extra layers of abstraction that could add cognitive overhead—especially when studying how prompts are constructed and used. That said, it's easy to imagine these functions being wrapped in Tool or Agent classes if desired.\n",
    "* State refers to a dictionary that stores variables shared across tools and not in LLM prompt construction.\n",
    "* AgentMemory is a data structure that keeps a record of the tools invoked, along with their parameters and responses. This information is used in various LLM prompts to help guide the model in generating more appropriate and context-aware responses.\n",
    "* All tools take these 3 parameters in addition to their own specific ones: (1) llm - instance of LLM (2) google_services - instance of google service class defined above (3) state - instance of state dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce905d6-f2bc-41ac-825c-d0d657fba88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(dict):\n",
    "    \"\"\"\n",
    "    Holds any data that may be required to be accessed between executing\n",
    "    the task plan steps or between the tools.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4774626b-7424-451c-b860-771a4ce1f4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentMemory:\n",
    "\n",
    "    \"\"\"\n",
    "    Keeps a record of the tools invoked, along with their parameters and responses. \n",
    "    This information is used in various LLM prompts as part of context.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.clear()\n",
    "\n",
    "    def add(self, task, response):\n",
    "        self.tasks.append(task)\n",
    "        self.responses.append(response)\n",
    "\n",
    "    def clear(self):\n",
    "        self.tasks = []\n",
    "        self.responses = []\n",
    "\n",
    "    def format(self):\n",
    "        data = []\n",
    "        for a, r in zip(self.tasks, self.responses):\n",
    "            item = f\"<tool_invoked>{a}</tool_invoked>\\n<tool_response>{r}</tool_response>\"\n",
    "            data.append(item)\n",
    "        return \"<items>\"+\"\".join(data)+\"</items>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6f1ca0-9ab3-4332-8f06-39e4cf90d975",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_between_tags(tag, string, strip = False):\n",
    "    \"\"\"\n",
    "    For Anthropic Claude models, wrapping output in XML (a similar markup) improves reliability of output parsing; \n",
    "    keeps free-form output separate from structured output (like json) and makes it easy to parse output without \n",
    "    relying on complex or brittle regular expressions. Following is a simple function that extracts content from given XML from the output.\n",
    "    \"\"\"\n",
    "    ext_list = re.findall(f\"<{tag}>(.+?)</{tag}>\", string, re.DOTALL)\n",
    "    if strip:\n",
    "        ext_list = [e.strip() for e in ext_list]\n",
    "    return ext_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab60cc9-ebb3-4c29-8718-0b65557721f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_meeting_request(llm, email_body):\n",
    "\n",
    "    \"\"\"\n",
    "    A function that uses an LLM to parse email body (which is in natural language)\n",
    "    and determine if it is a request for meeting and if so, return the meeting details\n",
    "    in a structured output that could be used by a deterministic code.\n",
    "    \"\"\"\n",
    "    \n",
    "    system_prompt = \"\"\"\n",
    "        You are an intelligent AI assistant designed to analyze the content of an email.\n",
    "        \n",
    "        Your task:\n",
    "        - Carefully read the provided email body.\n",
    "        - Determine if the email is a request for a meeting.\n",
    "        - If it is a meeting request, extract the following details:\n",
    "            - Subject of the meeting: a short phrase describing what the meeting is about.\n",
    "            - Proposed time or date: when the sender suggests holding the meeting (if mentioned).\n",
    "        - If the email is not a meeting request, respond with:\n",
    "            <output>\n",
    "            {\n",
    "                \"is_meeting_request\": false\n",
    "            }\n",
    "            </output>\n",
    "        \n",
    "        Extraction Guidelines:\n",
    "        - The subject should be derived from the purpose or key topic mentioned in the email.\n",
    "        - The time or date may be explicitly stated (e.g., “next Wednesday at 3 PM”) or implied (e.g., “early next week”). Extract this as-is, do not perform any computation on this.\n",
    "        - If the time is not given or not clear, leave the time field empty.\n",
    "        \n",
    "        Output format:\n",
    "        <output>\n",
    "        {\n",
    "            \"is_meeting_request\": true,\n",
    "            \"meeting_subject\": \"short subject line or key topic\",\n",
    "            \"proposed_time\": \"proposed date/time string or empty if not specified\",\n",
    "            \"duration\": \"duration or `60 minutes` if not specified\"\n",
    "        }\n",
    "        </output>\n",
    "    \"\"\"\n",
    "\n",
    "    user_prompt = f\"\"\"\n",
    "        Here is an email body:\n",
    "        \"{email_body}\"\n",
    "        \n",
    "        Please determine if this is a meeting request, and if yes, extract the meeting subject and proposed time.\n",
    "    \"\"\"\n",
    "\n",
    "    response = llm(system_prompt, user_prompt, True)\n",
    "\n",
    "    output = extract_between_tags(\"output\", \" \".join(response.split(\"\\n\")))[0]\n",
    "    return json.loads(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d883fa-be05-4449-9b3c-e3f42d3e20f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_message_body(llm, message):\n",
    "    \"\"\"\n",
    "    Use LLM to create a nice natural language description of scheduled meeting details\n",
    "    to be sent as reply to meeting schedule emails.\n",
    "    \"\"\"\n",
    "    \n",
    "    s = \"\"\"\n",
    "    Format the given message in readable English. Use bullet points and other formatting techiniques as necessary.\n",
    "    Be succinct.\n",
    "    Do not include explanations — only the formatted text.\n",
    "    \"\"\"\n",
    "    return llm(s, message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3ca984-851b-4c50-afcd-e098c5857cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Event(NamedTuple):\n",
    "    \"\"\"Represents an event with start and end date/time.\"\"\"\n",
    "    start_datetime: datetime\n",
    "    end_datetime: datetime\n",
    "\n",
    "def generate_available_slots(constraints):\n",
    "    \"\"\"\n",
    "    Finds the earliest available timeslot within the specified date range.\n",
    "    \n",
    "    Args:\n",
    "        start_date: The start date of the range to search\n",
    "        end_date: The end date of the range to search (inclusive)\n",
    "        events: List of existing events that might block timeslots\n",
    "        duration_minutes: Required duration of the timeslot in minutes\n",
    "    \n",
    "    Returns:\n",
    "        The start time of the earliest available timeslot, or None if none found\n",
    "\n",
    "    Warning: This function is not thoroughly vetted and there could be edge cases for which this won't work. The\n",
    "        purpose of this function is only to illustrate how a scheduling agent works and this function just \n",
    "        serves to help it as a demo only.\n",
    "    \"\"\"\n",
    "\n",
    "    current_dt = parser.isoparse(constraints[\"currentDateTime\"]).astimezone()\n",
    "    tzinfo = current_dt.tzinfo\n",
    "    \n",
    "    start_date = parser.isoparse(constraints[\"dateRange\"][\"start\"]).astimezone()\n",
    "    end_date = parser.isoparse(constraints[\"dateRange\"][\"end\"]).astimezone()\n",
    "\n",
    "    business_hours = constraints[\"businessHours\"]\n",
    "\n",
    "\n",
    "    # Office hours constraints\n",
    "    OFFICE_START_TIME = datetime.strptime(business_hours[\"start\"], \"%H:%M\").time()\n",
    "    OFFICE_END_TIME = datetime.strptime(business_hours[\"end\"], \"%H:%M\").time()\n",
    "    \n",
    "    # Lunch break constraints\n",
    "    LUNCH_START_TIME = datetime.strptime(business_hours[\"lunchBreakStart\"], \"%H:%M\").time()\n",
    "    LUNCH_END_TIME = datetime.strptime(business_hours[\"lunchBreakEnd\"], \"%H:%M\").time()\n",
    "    \n",
    "    # Convert duration to timedelta object\n",
    "    required_duration = timedelta(minutes=constraints[\"requiredDurationMinutes\"])\n",
    "\n",
    "    if required_duration <= timedelta(0):\n",
    "        return None\n",
    "        \n",
    "    events = [Event(start_datetime=parser.isoparse(event[\"start\"]).astimezone(), end_datetime=parser.isoparse(event[\"end\"]).astimezone())\n",
    "        for event in constraints[\"existingEventsSummary\"] ]\n",
    "\n",
    "    # Sort events by start time\n",
    "    sorted_events = sorted(events, key=lambda e: e.start_datetime)\n",
    "\n",
    "    print(f\"All sorted events {sorted_events}\")\n",
    "    \n",
    "    # Iterate through each day in the date range\n",
    "    current_date = start_date\n",
    "    while current_date <= end_date:\n",
    "\n",
    "        # Create time blocks for this day\n",
    "        day_start = datetime.combine(current_date, OFFICE_START_TIME, tzinfo)\n",
    "        lunch_start = datetime.combine(current_date, LUNCH_START_TIME, tzinfo)\n",
    "        lunch_end = datetime.combine(current_date, LUNCH_END_TIME, tzinfo)\n",
    "        day_end = datetime.combine(current_date, OFFICE_END_TIME, tzinfo)\n",
    "\n",
    "        if current_date >= end_date:\n",
    "            print(\"Could not find any\")\n",
    "            break\n",
    "            \n",
    "        print(f\"\\nChecking for day {day_start} - {day_end}\\n\\n\")\n",
    "\n",
    "        # Filter events for this day\n",
    "        day_events = []\n",
    "        for e in sorted_events:\n",
    "            print(f\"\\Checking  event : {e.start_datetime} - {e.end_datetime}\")\n",
    "            \n",
    "            if e.end_datetime <= day_start:\n",
    "                continue\n",
    "            if e.start_datetime >= day_end:\n",
    "                continue\n",
    "            day_events.append(e)\n",
    "            print(f\"\\tOverlapping event of the day: {e.start_datetime} - {e.end_datetime}\")\n",
    "            \n",
    "        print(f\"\\tExisting events on this day = {day_events}\")\n",
    "        \n",
    "        # Create a list of busy periods (including events and lunch)\n",
    "        busy_periods = []\n",
    "        \n",
    "        # Add lunch as a busy period\n",
    "        busy_periods.append((lunch_start, lunch_end))\n",
    "        \n",
    "        # Add events as busy periods\n",
    "        for event in day_events:\n",
    "            # Clip event times to office hours for this day\n",
    "            event_start = max(event.start_datetime, day_start)\n",
    "            event_end = min(event.end_datetime, day_end)\n",
    "            \n",
    "            # Only add if event is within office hours\n",
    "            if event_start < event_end:\n",
    "                busy_periods.append((event_start, event_end))\n",
    "        \n",
    "        # Sort busy periods by start time\n",
    "        busy_periods.sort()\n",
    "\n",
    "\n",
    "        # Merge overlapping busy periods\n",
    "        if busy_periods:\n",
    "            merged_periods = [busy_periods[0]]\n",
    "            for current_start, current_end in busy_periods[1:]:\n",
    "                prev_start, prev_end = merged_periods[-1]\n",
    "                if current_start <= prev_end:\n",
    "                    # Periods overlap, merge them\n",
    "                    merged_periods[-1] = (prev_start, max(prev_end, current_end))\n",
    "                else:\n",
    "                    # No overlap, add as new period\n",
    "                    merged_periods.append((current_start, current_end))\n",
    "            busy_periods = merged_periods\n",
    "\n",
    "        print(f\"\\tBusy periods = {busy_periods}\")\n",
    "        \n",
    "\n",
    "        # Find gaps between busy periods that are large enough\n",
    "        current_time = day_start\n",
    "        for busy_start, busy_end in busy_periods:\n",
    "            print(f\"\\tChecking if current time {current_time} falls in busy period: {busy_start} - {busy_end}\")\n",
    "            # If there's a gap before this busy period\n",
    "            if current_time < busy_start:\n",
    "                gap_duration = busy_start - current_time\n",
    "                if gap_duration >= required_duration:\n",
    "                    return current_time.isoformat()\n",
    "            \n",
    "            # Move current time to end of this busy period\n",
    "            current_time = busy_end\n",
    "        \n",
    "        # Check for gap after last busy period\n",
    "        if current_time < day_end:\n",
    "            gap_duration = day_end - current_time\n",
    "            if gap_duration >= required_duration:\n",
    "                return current_times.isoformat()\n",
    "        \n",
    "        # Move to next day\n",
    "        current_date += timedelta(days=1)\n",
    "    \n",
    "    # No available timeslot found\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791fbc58-8962-4ccd-80dc-dda982240248",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_email(llm, google_services, state, subject):\n",
    "\n",
    "    \"\"\"\n",
    "    A tool to read unread emails from google email inbox and generate structured output\n",
    "    for meeting requests.\n",
    "    \"\"\"\n",
    "    \n",
    "    search_id = google_services.gmail_service.users().messages().list(userId='me', labelIds=['INBOX', 'UNREAD']).execute()\n",
    "\n",
    "    number_result = search_id['resultSizeEstimate']\n",
    "    \n",
    "    if number_result > 0:\n",
    "        message_ids = search_id['messages']\n",
    "\n",
    "        for ids in message_ids[:MAX_EMAILS_TO_READ]:\n",
    "            print(\"Getting message with id:\", ids['id'])\n",
    "            message = google_services.get_message(ids['id'] )\n",
    "            mtg_req = check_meeting_request(llm, message['body'])\n",
    "            if mtg_req['is_meeting_request']:\n",
    "                mtg_req['from'] = message['from']\n",
    "                mtg_req['to'] = message['to']\n",
    "                # Let's store the message id in the state so later steps can use it (for example to mark it as read)\n",
    "                # It could potentially be stored in the mtg_request and passed on to subsequent steps,\n",
    "                # but that could pollute the LLM prompt context\n",
    "                state['message_id'] = ids['id']\n",
    "                return [mtg_req]\n",
    "\n",
    "    print('There were 0 results for that search string')\n",
    "    return \"There are no pending emails that require meeting scheduling\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2489de6-cf85-495a-b18c-bcfea73ae4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_calendar_availability(llm, google_services, state, criteria):\n",
    "\n",
    "    \"\"\"\n",
    "    A tool that goes through user's calendar, find current scheduled events, and based on them\n",
    "    find the next available time in the calendar.\n",
    "\n",
    "    Criteria is read from the email of meeting request and is in natural language\n",
    "    description. First uses LLM to convert this loosedly given criteria into a\n",
    "    structured set of constraints (JSON). Then searches the calendar for available\n",
    "    slots.\n",
    "    \"\"\"\n",
    "    \n",
    "    events = google_services.simple_events()\n",
    "    events_summary = json.dumps(events) # \"\\n\".join(_events_as_nls(events))\n",
    "\n",
    "    current = datetime.now().isoformat()\n",
    "\n",
    "    system_prompt = f\"\"\"\n",
    "    You are an intelligent AI assistant helping with calendar scheduling.\n",
    "    \n",
    "    <instructions>\n",
    "    - You will not perform time calculations.\n",
    "    - You are given current calendar events and the user's criteria.\n",
    "    - Your task is to:\n",
    "        - Identify constraints (date ranges, duration, preferred times of day).\n",
    "        - Structure those constraints clearly for backend processing.\n",
    "        - Specify required offsets (e.g., \"at least 1 hour from now\") and business-hour boundaries.\n",
    "        - Highlight exclusions (e.g., lunch breaks, existing events).\n",
    "    - Output constraints as a structured JSON object.\n",
    "    - Do not guess or calculate times — just reason and structure the information.\n",
    "    - Fill the \"start\" and \"end\" fields in \"dateRange\" with date/time in RFC3339 format. Make sure use the same timezone as given in the current date/time.\n",
    "    - Note that current date/time is given in RFC3339 format.\n",
    "    - When generating dates, always use an explicit offset from UTC.\n",
    "    \n",
    "    Current date and time: '{current}'\n",
    "    \n",
    "    Output format:\n",
    "    <constraints>\n",
    "    {{\n",
    "        \"currentDateTime\": \"{current}\",\n",
    "        \"businessHours\": {{\n",
    "            \"start\": \"08:00\",\n",
    "            \"end\": \"16:30\",\n",
    "            \"lunchBreakStart\": \"12:00\",\n",
    "            \"lunchBreakEnd\": \"13:30\"\n",
    "        }},\n",
    "        \"minOffsetFromNowMinutes\": 60,\n",
    "        \"requiredDurationMinutes\": \"parse duration from criteria converting into minutes\",\n",
    "        \"dateRange\": {{ \"start\": \"fill start date in RFC3339 format\", \"end\": \"fill end date in RFC3339 format\" }},\n",
    "        \"userPreferences\": \"{criteria}\",\n",
    "        \"existingEventsSummary\": {events_summary}\n",
    "    }}\n",
    "    </constraints>\n",
    "    \"\"\"\n",
    "\n",
    "    user_prompt = f\"\"\"\n",
    "    Here are the current calendar events: {events_summary}\n",
    "    User criteria: {criteria}\n",
    "    Please extract scheduling constraints for backend processing.\n",
    "    \"\"\"\n",
    "    \n",
    "    llm_slots = llm(system_prompt, user_prompt, True)\n",
    "    constraints_str  = extract_between_tags(\"constraints\", \" \".join(llm_slots.split(\"\\n\")))[0]\n",
    "    constraints_json = json.loads(constraints_str)\n",
    "\n",
    "    available_slots = generate_available_slots(constraints_json)\n",
    "\n",
    "    if available_slots is not None:\n",
    "        first_available_slot = available_slots\n",
    "    else:\n",
    "        first_available_slot = \"No slots available. Cannot reserve a time in calendar. Respond to email saying that no slots available in near future and check back again in a week.\"\n",
    "    return f\"<get_calendar_availability_response><constraints>{constraints_json}</constraints><first_available_slot>{first_available_slot}</first_available_slot></get_calendar_availability_response>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0ff654-ab9d-45ca-b7e4-c9ada1c70bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_email(llm, google_services, state, sender, to, subject, body):\n",
    "    formatted_body  = format_message_body(llm, body)\n",
    "    return google_services.send_message(sender, to, formatted_body, subject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a07a09b-03ce-48e4-af1d-d6db2c32f53c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def schedule_meeting(llm, google_services, state, subject, startDateTime, duration):\n",
    "    print(f\"Will mark message with id : {state['message_id']} as read\")\n",
    "    google_services.mark_message_read(state['message_id'])\n",
    "    return google_services.create_calendar_event(subject, startDateTime, duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e51f980-db07-492b-a538-3c653e96ae38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Description of tools availables. In a practical system, use something like OpenAPI speficiation and tool calling features of LLMs (like those provided by LLM Conversation API)\n",
    "\n",
    "tool_definitions = \"\"\"\n",
    "    <tools>\n",
    "        <tool>read_email — Read email; requires parameter `subject`</tool>\n",
    "        <tool>get_calendar_availability - Get the availability day abd time in the calendar based on proposed date/time (such as as week of the day,  daypart, expressions like next week, dayparts like morning / evening and so on) and/or duration (like 30 minutes, 2 hours and so on); requires parameter `criteria`</tool>\n",
    "        <tool>schedule_meeting - Schedues time on calendar for a meeting; requires parameters: `subject`, `startDateTime`, `duration` in minutes</tool>        \n",
    "        <tool>send_email — Send email; requires parameters `sender`, `to`, `subject`, `body`</tool>\n",
    "    </tools>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d80e927-c6c8-42ac-9b14-afb1a20ee044",
   "metadata": {},
   "outputs": [],
   "source": [
    "def task_planner_agent(tool_definitions, objective):\n",
    "    s = f\"\"\"\n",
    "    You are a Smart AI Task Planner. Your responsibility is to create a structured, step-by-step list of tasks that accomplish a user's objective.\n",
    "    Each task involves invoking one of the available tools with appropriate parameters.\n",
    "    You will not execute the tools — only build the plan.\n",
    "    \n",
    "    <instructions>\n",
    "        - Analyze the user's objective and break it down into tasks.\n",
    "        - Select appropriate tool(s) from the <tools> list for each task.\n",
    "        - Each tool may require one or more parameters\n",
    "        - Use parameters from:\n",
    "            - The user query\n",
    "            - Stored memory values\n",
    "        - Do not guess parameter values.\n",
    "        - Maintain correct order of tasks so outputs from previous tool invocations are always available before dependent tasks are executed.\n",
    "    </instructions>\n",
    "\n",
    "    {tool_definitions}\n",
    "\n",
    "    <checklist>\n",
    "      - All tool parameter_name and parameter_values are resolved through analizing user objective or memory.\n",
    "      - The plan is ordered logically and cleanly.\n",
    "      - Provide the final plan wrapped in a <plan> XML tag in the described JSON format.\n",
    "      - Choose the correct tools from the provided list.\n",
    "      - Create a step-by-step plan showing the order of tool calls.\n",
    "      - For each tool, list its parameters using parameter_name and parameter_value.\n",
    "    </checklist>\n",
    "\n",
    "    <output>\n",
    "        Output Format:\n",
    "        Output the plan inside a <plan> XML tag.\n",
    "        The plan is a JSON array of tool calls, where each tool call contains:\n",
    "        \"name\": The tool name\n",
    "        \"parameters\": An array of objects, each with:\n",
    "            \"parameter_name\"\n",
    "            \"parameter_value\"\n",
    "        Example output structure:\n",
    "            <plan>\n",
    "            [\n",
    "              {{\n",
    "                \"tool\": \"name of the tool\",\n",
    "                \"parameters\": [\n",
    "                    {{ \"parameter_name\": \"parameter_name\", \"parameter_value\": \"parameter_value\" }}\n",
    "                  ]\n",
    "              }}\n",
    "            ]\n",
    "            </plan>\n",
    "\n",
    "    </output>\n",
    "    \"\"\"\n",
    "    p = f\"\"\"\n",
    "        {objective}\n",
    "    \"\"\"\n",
    "    return llm(s, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd86c265-97c4-492e-92ba-f03a56b66a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_executable_plan(tool_definitions, objective):\n",
    "    llm_plan = task_planner_agent(tool_definitions, objective)\n",
    "    print(llm_plan)\n",
    "    all_tasks  = extract_between_tags(\"plan\", \" \".join(llm_plan.split(\"\\n\")))[0]\n",
    "    tasks = json.loads(all_tasks)\n",
    "    return tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd56a49e-2598-47c8-8502-81bbd0c17701",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tool_select_system_prompt(tool_definitions, agent_memory):\n",
    "    tool_select_system_prompt = f\"\"\"\n",
    "    You are an AI assistant helping the user accomplish a task by populating the parameter values of a tool.\n",
    "    \n",
    "    <instructions>\n",
    "        - Analyze the user's current tool.\n",
    "        - Reference the memory of previous tool executions and responses to inform parameter values.\n",
    "        - Choose the most appropriate parameter_names and parameter_values.\n",
    "        - You are only going to format the tool given in user's query. You are not going to select a different tool.\n",
    "    </instructions>\n",
    "\n",
    "    You have access to the previous calls to tools and their responses:\n",
    "    <memory>\n",
    "        {agent_memory.format()}\n",
    "    </memory>\n",
    "    \n",
    "    <checklist>\n",
    "    - Parameter values can come from:\n",
    "      - The current user query\n",
    "      - The output of previously used tools (referenced from memory)\n",
    "    \n",
    "    - If a tool does not require parameters, just leave parameter_name, parameter_value as empty strings.\n",
    "    - Only output one tool call at a time (if needed).\n",
    "    - If no tool is required for the user's query, return an empty tool value.\n",
    "    </checklist>\n",
    "\n",
    "    {tool_definitions}\n",
    "\n",
    "    <output>\n",
    "    Output only JSON in the following format:\n",
    "    \n",
    "    \n",
    "    {{\n",
    "      \"tool\": \"tool_name\",\n",
    "      \"parameters\": [\n",
    "        {{\n",
    "          \"parameter_name\": \"name_of_parameter\",\n",
    "          \"parameter_value\": \"value_from_memory\"\n",
    "        }}\n",
    "      ]\n",
    "    }}\n",
    "\n",
    "    </output>\n",
    "\n",
    "    No explanations or text outside the JSON.\n",
    "    \"\"\"\n",
    "\n",
    "    return tool_select_system_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c9aaa4-6c2a-46db-aba9-cd38a0c0ad71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def should_continue_with_plan(llm, plan, tool_definitions, agent_memory):\n",
    "    system_prompt = \"\"\"\n",
    "\n",
    "        You are an AI assistant helping the user accomplish an objective. A plan is created to achieve the objective in the\n",
    "        form of sequence of tools to be invoked. \n",
    "        Your goal is to analyze the plan, the tools executed so far, and the most recent tool execution and its response. Then you come up with\n",
    "        saying whether user should continue with the next task in the plan or stop because there is no way to continue based on the most recent tool\n",
    "        and its response.\n",
    "        \n",
    "        \n",
    "        <background>\n",
    "        - Review the tools already executed and their outputs.\n",
    "        - Compare that to the original tool sequence.\n",
    "        - Decide if the remaining sequence should be modified by:\n",
    "          - Removing redundant or no-longer-relevant tools\n",
    "          - Reordering for better flow        \n",
    "          - Adding new tools that are now needed based on output or failure\n",
    "        </instructions>\n",
    "        \n",
    "        <guidelines>\n",
    "        - Only keep tools that are still necessary.\n",
    "        - Add new tools if new subtasks have emerged.\n",
    "        - Make sure dependencies between tools are preserved.\n",
    "        </guidelines>\n",
    "\n",
    "        Here are the tools:\n",
    "        {tool_definitions}\n",
    "\n",
    "    Output only JSON using the <output> tags as given below:   \n",
    "\n",
    "    <output>\n",
    "    {{\n",
    "      \"continue\": \"yes or no\"\n",
    "    }}\n",
    "    </output>\n",
    "\n",
    "    Think step by step, output your thoughts in <thinking> tags.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    user_prompt = f\"\"\"\n",
    "    <plan>\n",
    "      {plan}\n",
    "    </plan>\n",
    "\n",
    "    <tools_executed_and_responses>\n",
    "            {agent_memory.format()}\n",
    "    </tools_executed_and_responses>\n",
    "\n",
    "    Last item in the tools_executed_and_responses points to the most recent tool execution and its response.\n",
    "    \"\"\"\n",
    "\n",
    "    response = llm(system_prompt, user_prompt, True)\n",
    "\n",
    "    flag_str  = extract_between_tags(\"output\", \" \".join(response.split(\"\\n\")))[0]\n",
    "    flag = json.loads(flag_str)    \n",
    "\n",
    "    if flag[\"continue\"] == \"yes\":\n",
    "        return True\n",
    "\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d859f7e-05eb-4299-985a-65c686b9b0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def invoke_tool(llm, google_services, state, func_name, params):\n",
    "    args = { param['parameter_name'] : param['parameter_value'] for param in params }\n",
    "    args[\"llm\"] = llm\n",
    "    args[\"google_services\"] =  google_services\n",
    "    args[\"state\"] = state\n",
    "    return globals()[func_name](**args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccab8aab-184c-4962-984f-251944cedd53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_task(llm, google_services, state, tools, tool_definitions, task, agent_memory):\n",
    "\n",
    "    task_str = json.dumps(task)\n",
    "    tool_select_system_prompt = get_tool_select_system_prompt(tool_definitions, agent_memory)\n",
    "    tool_to_invoke = llm(tool_select_system_prompt, task_str)\n",
    "\n",
    "    tool_to_invoke_json = json.loads(tool_to_invoke)\n",
    "\n",
    "    print(f\"Invoking tool {tool_to_invoke_json}\")\n",
    "\n",
    "    tool = tool_to_invoke_json.get(\"tool\")\n",
    "    parameters = tool_to_invoke_json.get(\"parameters\", [])\n",
    "\n",
    "    if tool in tools:\n",
    "        response = invoke_tool(llm, google_services, state, tool, parameters)\n",
    "        agent_memory.add(tool_to_invoke, f\"task `{tool}` completed, response = {response}\")\n",
    "    else:\n",
    "        print(\"Unknown tool: \", tool)\n",
    "\n",
    "    return\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0f04db-5f43-4a9a-a5c6-23320243ff6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_plan(llm, google_services, state, tools, tool_definitions, tasks, agent_memory):\n",
    "    print(\"----\\nInitial memory:\", agent_memory.format())\n",
    "\n",
    "    for i, task in enumerate(tasks):\n",
    "        print(\"--------\\nNext task to execute: \", task, \"\\n\\n\")\n",
    "        go = input(\"Continue?\")\n",
    "        if go == \"yes\":\n",
    "            pass\n",
    "        else:\n",
    "            break\n",
    "        \n",
    "        execute_task(llm, google_services, state, tools, tool_definitions, task, agent_memory)\n",
    "\n",
    "        # In general, depending on response (for example as simple as success vs. failure)\n",
    "        # from tool after execute_task you might want to do somethng different.\n",
    "        # There are atleast a couple of options (a) if-condition, but that is hard-wiring logic \n",
    "        # and need do in advance (b) have a replan prompt that helps to decide to do something else --\n",
    "        # like calling a different tool or asking to abort. But this could lead to hallucination\n",
    "        # and other gotchas -- requires more testing with plenty of datasets.\n",
    "        # With replanning, we may do something like this:\n",
    "        # pending_tasks = replan(tool_definitions, agent_memory, pending_tasks, task)\n",
    "\n",
    "        print(\"Memory after execution:\", agent_memory.format())\n",
    "        print(\"\\n\\n-----------\\n\\n\")\n",
    "\n",
    "        if i < len(tasks) - 1:\n",
    "            print(\"Checking if should continue with the plan...\")\n",
    "            continue_flag = should_continue_with_plan(llm, tasks, tool_definitions, agent_memory)\n",
    "    \n",
    "            if not continue_flag:\n",
    "                print(\"Agent determined there is no point continuing, so aborting the plan execution\")\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ecb2124-d11b-405a-822d-6b6df4a16c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_email_schedule_objective(subject):\n",
    "    objective = f\"\"\"\n",
    "    Here is my objective:\n",
    "        - I have a email requesting scheduling a meeting with me.\n",
    "        - Read the email with subject: {subject} and extract what the meeting is about, and when they wanted to schedule the meeting.\n",
    "        - Then check my calendar, to find available slots based on the criteria given in the email.\n",
    "        - Schedule the meeting in the calendar with the earliest available slot.\n",
    "        - Finally send a confirmation email to the original requestor using appropriate subject and body based on previous steps.\n",
    "    \"\"\"\n",
    "    return objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2550185e-deea-4669-b991-879255a62d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\"send_email\", \"read_email\", \"get_calendar_availability\", \"schedule_meeting\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23059c4c-1c13-46b2-9bab-938d287f919b",
   "metadata": {},
   "source": [
    "In this toy example, notice how objective and tools are lined up well with each other. This helps to reduce hallucinations when generating execution plan.\n",
    "\n",
    "In a more complex application the tools may be determined through a shortlisting process (which itself could leverage LLM/RAG techniques) for the current objective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e7e2dd-b398-4dc1-b125-e34919dca8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "bedrock_runtime_client = boto3.client(service_name=\"bedrock-runtime\", region_name=\"us-east-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c35c5ca-edf2-4d5f-967b-a612127ce408",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = Llm(bedrock_runtime_client, MODEL_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06495c04-e513-42bd-9a79-a64b120f6269",
   "metadata": {},
   "outputs": [],
   "source": [
    "google_services = GoogleServices(GOOGLE_CREDENTALS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a54dd71-cd84-4007-9117-81cb4d6881c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "objective = get_email_schedule_objective(\"schedule meeting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c10e171-b352-4773-83e1-8c30da57fa0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = create_executable_plan(tool_definitions, objective)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5a9e63-03d0-436b-b7e0-72ddb3a6936a",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_memory = AgentMemory()\n",
    "state = State()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d11ac61-19d3-4296-9370-bff8da4e4155",
   "metadata": {},
   "outputs": [],
   "source": [
    "execute_plan(llm, google_services, state, tools, tool_definitions, tasks, agent_memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394468bc-dbad-4bcc-a488-0aa4edb83ffb",
   "metadata": {},
   "source": [
    "Exercise\n",
    "---\n",
    "\n",
    "Modify should_continue_with_plan to be a richer replanning sub-agent. For example, if there are no timeslots available, instead of aborting, alter the plan (i.e., re-plan) to directly send email indicating so and asking to check back later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c48894f-9cf1-4c3f-973b-439bec7d4058",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter-env",
   "language": "python",
   "name": "jupyter-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
